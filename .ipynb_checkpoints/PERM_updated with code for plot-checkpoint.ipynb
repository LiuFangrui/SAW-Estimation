{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def PERM(L, C_plus = 10, C_minus = 1):\n",
    "    \"\"\"\n",
    "    Generates a self-avoiding walk (SAW) of length L using PERM.\n",
    "\n",
    "    The walk starts at the origin (0,0). At each step, valid moves are determined by ensuring no self-intersection.\n",
    "    The weight of a partial configuration is updated as the product of valid moves at each step.\n",
    "    Paths with weights below the pruning threshold are discarded with probability 0.5; surviving paths have their weight doubled.\n",
    "    Paths with weights above the enrichment threshold are split into multiple copies, each with reduced weight.\n",
    "    Completed walks contribute to the total weight estimate.\n",
    "    If L = 0, the function returns 1 directly as there is only one trivial walk of length 0.\n",
    "    The algorithm uses a stack to manage partial configurations.\n",
    "\n",
    "    Returns:\n",
    "        total_weights[L] (float): One value for the PERM estimate of c_L.\n",
    "    \"\"\"\n",
    "    # Special case: L = 0\n",
    "    if L == 0:\n",
    "        return 1\n",
    "\n",
    "    # Thresholds\n",
    "    Z_hat = [1] * (L + 1)  # Z_hat[i] is the estimate of Z for length i, initialised to 1 for all i in [0, L]\n",
    "\n",
    "    def W_plus(n):\n",
    "        return C_plus * Z_hat[n]\n",
    "    \n",
    "    def W_minus(n):\n",
    "        return C_minus * Z_hat[n]\n",
    "\n",
    "    # Initialise a stack: (path, path set, total weight, total walks)\n",
    "    stack = [([(0,0)], {(0,0)}, 1, 0)]  # Start at the origin with weight 1 and length 0\n",
    "    total_weights = np.zeros(L + 1)  # Stores the total weight of each length, initialised to 0\n",
    "    total_walks = np.zeros(L + 1)  # Stores the total number of walks of each length, initialised to 0\n",
    "\n",
    "    while stack:\n",
    "        # Pop the last item from the stack\n",
    "        path, path_set, weight, n = stack.pop()\n",
    "        if n == L: # Reached the target length\n",
    "            continue\n",
    "        \n",
    "        # Not reached the target length yet, so we need to generate valid moves\n",
    "        last_pos = path[-1] # Get the last position in the path\n",
    "        valid_moves = []\n",
    "        for dx, dy in [(1,0), (-1,0), (0,1), (0,-1)]: # Possible moves (Right, Left, Up, Down)\n",
    "            # Check if the new position is valid (not visited)\n",
    "            new_pos = (last_pos[0] + dx, last_pos[1] + dy)\n",
    "            if new_pos not in path_set:\n",
    "                valid_moves.append(new_pos)\n",
    "        w_n = len(valid_moves) # Number of valid moves\n",
    "        if w_n == 0:\n",
    "            continue  # Attrition, move to next iteration\n",
    "        \n",
    "        # Valid moves is not 0, update weight\n",
    "        new_weight = weight * w_n\n",
    "        move = random.choice(valid_moves)  # Randomly select a move from the valid moves\n",
    "        new_path = path + [move]  # Add the new move to the path\n",
    "        new_path_set = set(path_set)\n",
    "        new_path_set.add(move)\n",
    "        new_n = n+1\n",
    "\n",
    "        # Pruning/enrichment\n",
    "        if new_weight < W_minus(new_n):\n",
    "            # Weight too low, prune with probability 0.5\n",
    "            if np.random.rand() < 0.5:\n",
    "                continue  # Prune and move to the next iteration\n",
    "            else:\n",
    "                new_weight *= 2 # Survives pruning, balance out the weight of pruned paths\n",
    "        elif new_weight > W_plus(new_n): # Good path, enrich it\n",
    "            k = 2 # Total number of copies\n",
    "            for _ in range(k):\n",
    "                stack.append((new_path, new_path_set, new_weight / k, new_n)) # Add the new path to the stack k times\n",
    "                # Update Z_hat (partition sum) for both copies\n",
    "                total_walks[new_n] += 1\n",
    "                total_weights[new_n] += new_weight / k\n",
    "                Z_hat[new_n] = total_weights[new_n] / total_walks[new_n] if total_walks[new_n] > 0 else 0\n",
    "            continue\n",
    "        \n",
    "        # Didn't prune or enrich, just add the new path to the stack\n",
    "        stack.append((new_path, new_path_set, new_weight, new_n))\n",
    "        # Update Z_hat\n",
    "        total_walks[new_n] += 1\n",
    "        total_weights[new_n] += float(new_weight)\n",
    "        Z_hat[n+1] = total_weights[new_n] / total_walks[new_n] if total_walks[new_n] > 0 else 0\n",
    "    \n",
    "    return total_weights[L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated c_1: 4.0\n",
      "Estimated c_2: 12.0\n",
      "Estimated c_3: 36.0\n",
      "Estimated c_4: 100.00512\n",
      "Estimated c_5: 283.96926\n",
      "Estimated c_6: 780.243705\n",
      "Estimated c_7: 2170.2178125\n",
      "Estimated c_8: 5916.2543775\n",
      "Estimated c_9: 16292.143625625\n",
      "Estimated c_10: 44110.097656875\n"
     ]
    }
   ],
   "source": [
    "# Compute Monte Carlo estimates for c_L for L = 0 to 10 using 100,000 samples per length\n",
    "for i in range(1,11):\n",
    "    samples = [PERM(i) for _ in range(100000)]\n",
    "    print(f\"Estimated c_{i}: {np.mean(samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/1_hjt9tj3ld1dlyz59pwm3dm0000gn/T/ipykernel_16242/959225072.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mu_hats.append(cL_hat**(1/L))\n"
     ]
    }
   ],
   "source": [
    "# Estimate c_L up to L = 700 and plot the graph of mu estimate against L\n",
    "# c_L approximates mu^L, mu hat = c_L^(1/L)\n",
    "\n",
    "L_values = list(np.arange(51))\n",
    "L_values.extend(list(np.arange(100, 701, 100)))\n",
    "\n",
    "mu_hats = []\n",
    "\n",
    "# 10,000 samples for each L value (takes too long for 100,000)\n",
    "for L in L_values:\n",
    "    samples = [PERM(L, C_plus=50, C_minus=5) for _ in range(10000)]\n",
    "    cL_hat = np.mean(samples)\n",
    "    mu_hats.append(cL_hat**(1/L))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot mu_hats against L\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(L_values, mu_hats, marker='o', linestyle='-', label = 'μ(L)')\n",
    "plt.xlabel('L (Walk Length)')\n",
    "plt.ylabel('μ')\n",
    "plt.title('How μ changes with Walk Length L using PERM')\n",
    "\n",
    "# add annotations for each point from L=100 onwards\n",
    "for i in range(len(L_values)-7, len(L_values)):\n",
    "    plt.annotate(f'{mu_hats[i]:.2f}', \n",
    "                 xy=(L_values[i], mu_hats[i]),\n",
    "                 xytext=(5, 5), \n",
    "                 textcoords='offset points',\n",
    "                 fontsize=9\n",
    "                )\n",
    "    \n",
    "    \n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
